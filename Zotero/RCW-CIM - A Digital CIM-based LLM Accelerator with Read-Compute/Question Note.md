### Q1.RCW具體過程為何?
過去的 CIM 確實傾向把權重「一次性」固定在 SRAM 陣列中，藉由避免資料移動來達到極致的省電。但面對大型語言模型動輒數十 GB 的龐大權重，單一晶片的 SRAM 根本裝不下。因此，設計者必須將龐大的矩陣「切塊」，透過你注意到的 Weight Buffer 將資料分流，讓運算變成一個動態的流水線 (Pipeline) 。

這個「動態化」正是 RCW (Read-Compute/Write) 能把等待時間隱藏起來的秘密：當系統正在用「當下的權重」進行矩陣運算時，Weight Buffer 已經在把「下一批權重」悄悄寫入陣列中備用了。

---
### Q2.為什麼能夠有好的nonlinear operation fusion capability?
在傳統的 CIM 架構中，當硬體算完一部分的矩陣結果後，通常必須先把這些「半成品（部分和）」送回遙遠且慢速的外部記憶體 (DRAM) 存放。等到整批矩陣都算完，再從 DRAM 讀出來餵給另一個單元去算 Softmax。因為資料頻繁進出晶片，處理過程被打斷，自然就無法把這些運算步驟「融合」成一個不間斷的流水線。

這完美解釋了為什麼我們需要 **Output-Column-Stationary (OCS)** 資料流。如果沒有把這些先算出來的「半成品（$x_1, x_2...$）」留在晶片內，我們就得把它們全部丟回外接記憶體 (DRAM) 存放，等最後一個數字算完後，再全部讀回來算 Softmax。這來回搬運的延遲 (Latency) 會徹底摧毀系統效能。

